filename <- list()
# Specify names for data file, Excel attribute/constraints specs, and output
out_prefix <- "Teneo2" # YOUR name for output files (prefix)
filename$conjoint <- "SingleCSVFinal_TestBadNames.csv" # YOUR .csv or .rds with extension
filename$specs <- "Coding_and_Constraints_BadNames.xlsx" # YOUR Coding and constraints file
filename$cov <- NULL # NULL if No Covariates. OPTIONAL file has id as 1st column
# 2) Read Data into R =============
if (!file.exists(file.path(dir$data, filename$specs))){ # Read excel specs
message(paste0("Cannot find your Excel specs file: ", filename$specs))
} else {
specs_att_coding <- data.frame(read_xlsx(file.path(dir$data,filename$specs), sheet = "Att_Coding",
col_types = c("text","text","numeric")))
specs_pair_constraints <- data.frame(read_xlsx(file.path(dir$data,filename$specs), sheet = "Pair_Constraints",
col_types = c("text","numeric","numeric")))
specs_cov_coding <- data.frame(read_xlsx(file.path(dir$data,filename$specs),
sheet = "Cov_Coding", col_types = c("text","text")))
message("\nREAD SPECS INTO R files:\n")
message("specs_att_coding"); print(specs_att_coding)
message("\nspecs_pair_constraints"); print(specs_pair_constraints)
message("\nspecs_cov_coding"); print(specs_cov_coding);
data_conjoint <- read_csv_rds(dir$data, filename$conjoint, "as data_conjoint") # Reads in (csv or rds)
data_cov <- read_csv_rds(dir$data, filename$cov, "as data_cov") # Reads in (csv or rds)
}
col_id_task_dep <- c(1,2,ncol(data_conjoint)) # Columns for id, task, dep
# 3) Code and Prepare =============
indcode_spec <- indcode_spec_files(data_conjoint, specs_att_coding,
specs_pair_constraints) # Code and constraints each attribute
# Here is where you would do any custom coding indcode_spec[[i]] <- "syntax"
indcode_list <- make_codefiles(indcode_spec) # Combine specifications above into one list
save_codemastercon(indcode_list,dir$work, out_prefix) # Save combined code_master and constraints
data_stan <- prep_file_stan(idtaskdep = data_conjoint[,col_id_task_dep],
indcode_list)
if (!is.null(data_cov)){ # Code respondent covariates
data_stan$i_cov <- code_covariates(data_cov, specs_cov_coding, data_stan$resp_id)
data_stan$P_cov <- ncol(data_stan$i_cov) # Num of coded parameters
}
# 4) Modeling Options =============
# Specify multi-threading Stan and R
threads_per_chain <- min(max(1,(detectCores() - 2)/2), round(.5 + data_stan$T/(1000)), 24)
r_cores <- min(10,max(detectCores() -1,1)) # Number of cores to use for R
rm(indcode_spec); rm(indcode_list); gc()
#==================
# Modeling parameters. Defaults are usually fine
data_model <- list(
iter_warmup = 400, # warmup of 400 is plenty
iter_sampling = 400, # sampling of 400 is plenty
df = 2,              # recommend df = 2 for Wishart
prior_cov_scale = 1, # default 1
splitsize = round(.5 + data_stan$T/(4 * threads_per_chain)), # Tasks per core
agg_model = NULL, tag = NULL, ind = NULL
)
# 5) Estimate Model =============
#####  Specify Stan Model
stan_file <- "BaseHB_wPairCon_v2.1.stan" # Name of stan model in dir$stanmodel
stan_outname <- paste0(out_prefix, "_StanOut_",
format(Sys.time(), '%Y%m%d-%H%M%S')) # Base Name of Stan Output files
#####  Run Stan Model
HB_model <- cmdstan_model(file.path(dir$stanmodel,stan_file), quiet = TRUE,
cpp_options = list(stan_threads = TRUE))
message_estimation(dir, stan_outname)
HB_fit <- HB_model$sample(modifyList(data_stan, data_model),
iter_warmup = data_model$iter_warmup,
iter_sampling = data_model$iter_sampling,
output_dir = dir$stanout,
output_basename = stan_outname,
chains = 2,
parallel_chains = 2,
threads_per_chain = threads_per_chain,
save_warmup = TRUE,
refresh = 10,
adapt_delta = .8,
seed = 271,
init = .1,
show_messages = FALSE,
validate_csv = FALSE)
saveRDS(HB_fit, file.path(dir$work, "HB_fit.rds"))
#####  Check Convergence, Export Files
if (max(HB_fit$return_codes() == 0)){
checkconverge_export(stan_outname, data_stan$code_master, data_stan$resp_id,
nchains = HB_fit$num_chains(), dir$stanout, out_prefix, dir$work)
} else message("Stan Estimation Did not Finish")
env_modfun$PredMNL
View(utilities)
t <- 1
U <- exp(data_stan$ind %*% utilities[data_stan$task_individual[t],])
U <- exp(data_stan$ind[data_stan$start:data_stan$end,] %*% utilities[data_stan$task_individual[t],])
U <- exp(data_stan$ind[data_stan$start[t]:data_stan$end[t],] %*% utilities[data_stan$task_individual[t],])
env_stan$predMNL <- function(data_stan, utilities){
pred_all <- do.call(rbind, lapply(1:data_stan$T,
function(t){
U <- exp(data_stan$ind[data_stan$start[t]:data_stan$end[t],] %*%
utilities[data_stan$task_individual[t],])
pred <- U/sum(U)
return(pred)
}
)) # lapply, rbind
}
env_stan$predMNL
check_con <- utilities %*% data_stan$paircon_rows
check_con <- utilities %*% t(data_stan$paircon_rows)
t(data_stan$paircon_rows)
check_con <- utilities %*% t(data_stan$paircon_matrix)
View(check_con)
check_con <- (utilities %*% t(data_stan$paircon_matrix)) < 0
check_con <- rowSums(utilities %*% t(data_stan$paircon_matrix)) < 0
check_con <- rowSums(((utilities %*% t(data_stan$paircon_matrix)) < 0))
bad_ids <- rowSums(((utilities %*% t(data_stan$paircon_matrix)) < 0)) > 0
sum(bad_ids)
bad_ids[c(2,5)] <- TRUE
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " had reversals from constraints. IDs:"))
data_stan$resp_id[bad_ids]
}
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " respondents had reversals from constraints/n. IDs:"))
data_stan$resp_id[bad_ids]
}
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " respondents had reversals from constraints\n. IDs:"))
data_stan$resp_id[bad_ids]
}
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " respondents had reversals from constraints.\nIDs:"))
data_stan$resp_id[bad_ids]
}
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " respondents had reversals from constraints.\nIDs:"))
cat(data_stan$resp_id[bad_ids])
}
bad_ids <- rowSums(((utilities %*% t(data_stan$paircon_matrix)) < 0)) > 0
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " respondents had reversals from constraints.\nIDs:"))
cat(data_stan$resp_id[bad_ids])
}
bad_ids <- rowSums(((utilities %*% t(data_stan$paircon_matrix)) < 0)) > 0
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " respondents had reversals from constraints.\nIDs:"))
cat(data_stan$resp_id[bad_ids])
} else message("All respondent utilities obey constraints")
# Check if utilities meet constraints
bad_ids <- rowSums(((utilities %*% t(data_stan$paircon_matrix)) < 0)) > 0
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " respondents had reversals from constraints.\nIDs:"))
cat(data_stan$resp_id[bad_ids])
} else message("All respondent utilities obey constraints")
# Compute predictions
pred_all <- do.call(rbind, lapply(1:data_stan$T,
function(t){
U <- exp(data_stan$ind[data_stan$start[t]:data_stan$end[t],] %*%
utilities[data_stan$task_individual[t],])
pred <- U/sum(U)
return(pred)
}
)) # lapply, rbind
LL_id <- rowsum(log(predprob) * data_stan$dep * data_stan$wts, data_stan$match_id)
LL_id <- rowsum(log(pred_all) * data_stan$dep * data_stan$wts, data_stan$match_id)
sum_wts <- rowsum(data_stan$dep * data_stan$wts, data_stan$match_id)
sum_wts[sum_wts == 0] <- 1
rlh <- exp(LL_id/sum_wts)
util_name <- paste0(out_prefix,"_utilities_r.csv")
pred_name <- paste0(out_prefix,"_preds_mean_pt.csv")
pred_name <- paste0(out_prefix,"_preds_meanpt.csv")
message(paste0(
"\nSaving: \n",
" respondent point estimates with id and rlh: ", util_name,"\n",
" predictions for all data rows             : ", pred_name
))
write.table(cbind(id = resp_id, rlh = rlh, utilities_r), file = file.path(dir_work, util_name), sep = ",", na = ".", row.names = FALSE)
dir_work <- dir$work
write.table(cbind(id = data_stan$resp_id, rlh = rlh, utilities_r), file = file.path(dir_work, util_name), sep = ",", na = ".", row.names = FALSE)
utilities_r <- utilities %*% t(code_master)
utilities_r <- utilities %*% t(data_stan$code_master)
util_name <- paste0(out_prefix,"_utilities_r.csv")
pred_name <- paste0(out_prefix,"_preds_meanpt.csv")
write.table(cbind(id = data_stan$resp_id, rlh = rlh, utilities_r), file = file.path(dir_work, util_name), sep = ",", na = ".", row.names = FALSE)
dir_work
look <- cbind(id = data_stan$resp_id, rlh = rlh, utilities_r)
View(look)
look <- data.frame(cbind(id = data_stan$resp_id, rlh = rlh, utilities_r))
View(look)
look <- cbind(id = data_stan$resp_id, rlh = rlh, utilities_r)
look <- cbind(rlh = rlh, utilities_r)
View(look)
look <- cbind(rlh = as.matrix(rlh), utilities_r)
View(look)
look <- cbind(rlh = data_stan$resp_id, utilities_r)
View(look)
look <- cbind(id = data_stan$resp_id, rlh = exp(LL_id/sum_wts))
View(look)
colnames(header) <- c("id","rlh")
header <- cbind(id = data_stan$resp_id, rlh = exp(LL_id/sum_wts))
colnames(header) <- c("id","rlh")
write.table(cbind(header, utilities_r), file = file.path(dir_work, util_name), sep = ",", na = ".", row.names = FALSE)
bad_ids <- c("FailCon", NA)[bad_ids + 1]
# Check if utilities meet constraints
bad_ids <- rowSums(((utilities %*% t(data_stan$paircon_matrix)) < 0)) > 0
bad_ids + 1
bad_ids <- c(NA, "FailCon")[bad_ids + 1]
# Check if utilities meet constraints
bad_ids <- rowSums(((utilities %*% t(data_stan$paircon_matrix)) < 0)) > 0
bad_ids <- c("", "FailCon")[bad_ids + 1]
# Check if utilities meet constraints
bad_ids <- rowSums(((utilities %*% t(data_stan$paircon_matrix)) < 0)) > 0
FailCon <- c(NA, 1)[bad_ids + 1]
header <- cbind(id = data_stan$resp_id, rlh = exp(LL_id/sum_wts), FailCon)
View(header)
colnames(header) <- c("id","rlh","FailCon")
header <- cbind(id = data_stan$resp_id, rlh = exp(LL_id/sum_wts), FailCon)
colnames(header) <- c("id","rlh","FailCon")
message(paste0(
"\nSaving: \n",
" respondent point estimates     : ", util_name,"\n",
" predictions for all data rows  : ", pred_name
))
write.table(cbind(header, utilities_r), file = file.path(dir_work, util_name), sep = ",", na = ".", row.names = FALSE)
write.table(cbind(data_stan$idtask, data_stan$dep, data_stan$wts, pred_all), file = file.path(dir_work, pred_name), sep = ",", na = ".", row.names = FALSE)
util_failcon <- paste0(out_prefix,"_utilities_failcon.csv")
# Check if utilities meet constraints
bad_ids <- rowSums(((utilities %*% t(data_stan$paircon_matrix)) < 0)) > 0
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " respondents had reversals from constraints.\n",
"Saved to: ", failcon_name))
write.table(cbind(header, utilities_r)[bad_ids,], file = file.path(dir_work, failcon_name), sep = ",", na = ".", row.names = FALSE)
} else message("All respondent point utilities obey constraints")
bad_ids[c(2,4)] <- TRUE
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " respondents had reversals from constraints.\n",
"Saved to: ", failcon_name))
write.table(cbind(header, utilities_r)[bad_ids,], file = file.path(dir_work, failcon_name), sep = ",", na = ".", row.names = FALSE)
} else message("All respondent point utilities obey constraints")
failcon_name <- paste0(out_prefix,"_utilities_failcon.csv")
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " respondents had reversals from constraints.\n",
"Saved to: ", failcon_name))
write.table(cbind(header, utilities_r)[bad_ids,], file = file.path(dir_work, failcon_name), sep = ",", na = ".", row.names = FALSE)
} else message("All respondent point utilities obey constraints")
header <- cbind(id = data_stan$resp_id, rlh = exp(LL_id/sum_wts))
colnames(header) <- c("id","rlh")
message(paste0(
"\nSaving: \n",
" respondent point estimates     : ", util_name,"\n",
" predictions for all data rows  : ", pred_name
))
write.table(cbind(header, utilities_r), file = file.path(dir_work, util_name), sep = ",", na = ".", row.names = FALSE)
write.table(cbind(data_stan$idtask, data_stan$dep, data_stan$wts, pred_all), file = file.path(dir_work, pred_name), sep = ",", na = ".", row.names = FALSE)
# Check if utilities meet constraints
bad_ids <- rowSums(((utilities %*% t(data_stan$paircon_matrix)) < 0)) > 0
bad_ids[c(2,4)] <- TRUE
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " respondents had reversals from constraints.\n",
"Saved to: ", failcon_name))
write.table(cbind(header, utilities_r)[bad_ids,], file = file.path(dir_work, failcon_name), sep = ",", na = ".", row.names = FALSE)
} else message("All respondent point utilities obey constraints")
env_stan$checkconverge_export <- function(stan_outname, code_master, resp_id, nchains, dir_stanout, out_prefix, dir_work){
cat("Reading draws from Stan csv output into R (large files take time)...")
csv_name <- do.call(c, lapply(1:nchains, function(i) paste0(stan_outname,"-",i,".csv")))
draws_beta <- read_cmdstan_csv(file.path(dir_stanout, csv_name), variables = "beta_ind", format = "draws_list")
cat("DONE")
### Save output files and check convergence ###
draws_name <- paste0(out_prefix,"_draws_beta.rds")
pdf_name <- paste0(out_prefix,"_trace_plots.pdf")
fit_name <-  paste0(out_prefix,"_fit_stats.csv")
message(paste0(
"\nSaving post warm-up files for:\n",
" draws of utilities as R list:  ", draws_name,"\n",
" convergence stats of mean:     ", fit_name, "\n",
" PDF of detailed traceplots:    ", pdf_name,"\n",
"\nShowing post warm-up:\n",
" Acceptance rate across iterations (histogram)\n",
" Traceplots of all mean utilities together (Sawtooth chart)"
))
hist(do.call(rbind,draws_beta$post_warmup_sampler_diagnostics)$accept_stat__, breaks = 30, main = "Acceptance Rate - Sampling", xlab = "", xlim = c(0,1))
saveRDS(modifyList(draws_beta,list(warmup_draws = NULL)), file.path(dir_work, draws_name)) # drop warmup
.GlobalEnv$draws_beta <- modifyList(draws_beta,list(warmup_draws = NULL))
utilities <- matrix(
Reduce("+",lapply(draws_beta$post_warmup_draws, colMeans))/nchains,
length(resp_id), ncol(code_master),
byrow = TRUE) # First P entries are respondent 1, next P are resp 2
.GlobalEnv$utilities <- utilities
# Convergence charts saved as pdf and in fit_stats
fit_stats <- data.frame(
variable = colnames(code_master),
mean = NA,
rhat = NA,
ESS = NA
)
ndraws <- nrow(draws_beta$post_warmup_draws[[1]])
draws_beta_mu <- list() # Creates the mean of respondent utilities for each iteration, like alpha
for (chain_i in (1:nchains)){
draws_beta_list <- as.matrix(draws_beta$post_warmup_draws[[chain_i]])
draws_beta_mu[[chain_i]] <- t(sapply(1:ndraws, function(draw){
beta_mu <- colMeans(matrix(draws_beta_list[draw,],
length(resp_id), ncol(code_master), byrow = TRUE))
}))
#matplot(1:nrow(draws_beta_mu[[chain_i]]), draws_beta_mu[[chain_i]],
#        type = "l" , lty = 1, lwd = 1, main = paste0("Chain ", chain_i), xlab = "Iteration", ylab = "Mean Beta")
}
pdf(file = file.path(dir_work, pdf_name),   # The directory you want to save the file in
width = 7, # The width of the plot in inches
height = 5) # The height of the plot in inches
hist(do.call(rbind,draws_beta$post_warmup_sampler_diagnostics)$accept_stat__, breaks = 30, main = "Acceptance Rate - Sampling", xlab = "", xlim = c(0,1))
for (chain_i in (1:nchains)){
matplot(1:nrow(draws_beta_mu[[chain_i]]), draws_beta_mu[[chain_i]],
type = "l" , lty = 1, lwd = 1, main = paste0("Chain ", chain_i), xlab = "Iteration", ylab = "Mean Beta")
}
chain_cols <- c("red","blue","green","black")
for (i in 1:ncol(draws_beta_mu[[1]])){
x <- sapply(1:length(draws_beta_mu), function(chain){
draws_beta_mu[[chain]][,i]
}) # x is set of column i across draws_beta_mu
fit_stats$mean[i] <- round(mean(x), 2)
fit_stats$rhat[i] <- round(rhat(x),2)
fit_stats$ESS[i] <- round(ess_basic(x),1)
plot(x[,1], type = "l", col = chain_cols[1], ylim = c(min(x), max(x)),
xlab = "Sample Iteration", ylab = "Mean Beta",
main = paste(colnames(code_master)[i],
"| rhat = ", round(rhat(x),2),
"| ESS = ", round(ess_basic(x),1)
))
for (chain in 2:nchains){
lines(x[,2], type = "l", col = chain_cols[chain])
}
}
dev.off()
write.table(fit_stats, file = file.path(dir_work, paste0(out_prefix,"_fit_stats.csv")), sep = ",", na = ".", row.names = FALSE)
}
env_stan$process_utilities <- function(data_stan, utilities, out_prefix, dir_work){
# Compute predictions
pred_all <- do.call(rbind, lapply(1:data_stan$T,
function(t){
U <- exp(data_stan$ind[data_stan$start[t]:data_stan$end[t],] %*%
utilities[data_stan$task_individual[t],])
pred <- U/sum(U)
return(pred)
}
)) # lapply, rbind
utilities_r <- utilities %*% t(data_stan$code_master)
util_name <- paste0(out_prefix,"_utilities_r.csv")
pred_name <- paste0(out_prefix,"_preds_meanpt.csv")
failcon_name <- paste0(out_prefix,"_utilities_failcon.csv")
LL_id <- rowsum(log(pred_all) * data_stan$dep * data_stan$wts, data_stan$match_id)
sum_wts <- rowsum(data_stan$dep * data_stan$wts, data_stan$match_id)
sum_wts[sum_wts == 0] <- 1
header <- cbind(id = data_stan$resp_id, rlh = exp(LL_id/sum_wts))
colnames(header) <- c("id","rlh")
message(paste0(
"\nSaving: \n",
" respondent point estimates     : ", util_name,"\n",
" predictions for all data rows  : ", pred_name
))
write.table(cbind(header, utilities_r), file = file.path(dir_work, util_name), sep = ",", na = ".", row.names = FALSE)
write.table(cbind(data_stan$idtask, data_stan$dep, data_stan$wts, pred_all), file = file.path(dir_work, pred_name), sep = ",", na = ".", row.names = FALSE)
# Check if utilities meet constraints
bad_ids <- rowSums(((utilities %*% t(data_stan$paircon_matrix)) < 0)) > 0
bad_ids[c(2,4)] <- TRUE
if (sum(bad_ids) > 0){
message(paste0(sum(bad_ids), " respondents had reversals from constraints.\n",
"Saved to: ", failcon_name))
write.table(cbind(header, utilities_r)[bad_ids,], file = file.path(dir_work, failcon_name), sep = ",", na = ".", row.names = FALSE)
} else message("All respondent point utilities obey constraints")
}
env_stan$checkconverge_export <- function(stan_outname, code_master, nresp, nchains, dir_stanout, out_prefix, dir_work){
cat("Reading draws from Stan csv output into R (large files take time)...")
csv_name <- do.call(c, lapply(1:nchains, function(i) paste0(stan_outname,"-",i,".csv")))
draws_beta <- read_cmdstan_csv(file.path(dir_stanout, csv_name), variables = "beta_ind", format = "draws_list")
cat("DONE")
### Save output files and check convergence ###
draws_name <- paste0(out_prefix,"_draws_beta.rds")
pdf_name <- paste0(out_prefix,"_trace_plots.pdf")
fit_name <-  paste0(out_prefix,"_fit_stats.csv")
message(paste0(
"\nSaving post warm-up files for:\n",
" draws of utilities as R list:  ", draws_name,"\n",
" convergence stats of mean:     ", fit_name, "\n",
" PDF of detailed traceplots:    ", pdf_name,"\n",
"\nShowing post warm-up:\n",
" Acceptance rate across iterations (histogram)\n",
" Traceplots of all mean utilities together (Sawtooth chart)"
))
hist(do.call(rbind,draws_beta$post_warmup_sampler_diagnostics)$accept_stat__, breaks = 30, main = "Acceptance Rate - Sampling", xlab = "", xlim = c(0,1))
saveRDS(modifyList(draws_beta,list(warmup_draws = NULL)), file.path(dir_work, draws_name)) # drop warmup
.GlobalEnv$draws_beta <- modifyList(draws_beta,list(warmup_draws = NULL))
utilities <- matrix(
Reduce("+",lapply(draws_beta$post_warmup_draws, colMeans))/nchains,
nresp, ncol(code_master),
byrow = TRUE) # First P entries are respondent 1, next P are resp 2
.GlobalEnv$utilities <- utilities
# Convergence charts saved as pdf and in fit_stats
fit_stats <- data.frame(
variable = colnames(code_master),
mean = NA,
rhat = NA,
ESS = NA
)
ndraws <- nrow(draws_beta$post_warmup_draws[[1]])
draws_beta_mu <- list() # Creates the mean of respondent utilities for each iteration, like alpha
for (chain_i in (1:nchains)){
draws_beta_list <- as.matrix(draws_beta$post_warmup_draws[[chain_i]])
draws_beta_mu[[chain_i]] <- t(sapply(1:ndraws, function(draw){
beta_mu <- colMeans(matrix(draws_beta_list[draw,],
nresp, ncol(code_master), byrow = TRUE))
}))
#matplot(1:nrow(draws_beta_mu[[chain_i]]), draws_beta_mu[[chain_i]],
#        type = "l" , lty = 1, lwd = 1, main = paste0("Chain ", chain_i), xlab = "Iteration", ylab = "Mean Beta")
}
pdf(file = file.path(dir_work, pdf_name),   # The directory you want to save the file in
width = 7, # The width of the plot in inches
height = 5) # The height of the plot in inches
hist(do.call(rbind,draws_beta$post_warmup_sampler_diagnostics)$accept_stat__, breaks = 30, main = "Acceptance Rate - Sampling", xlab = "", xlim = c(0,1))
for (chain_i in (1:nchains)){
matplot(1:nrow(draws_beta_mu[[chain_i]]), draws_beta_mu[[chain_i]],
type = "l" , lty = 1, lwd = 1, main = paste0("Chain ", chain_i), xlab = "Iteration", ylab = "Mean Beta")
}
chain_cols <- c("red","blue","green","black")
for (i in 1:ncol(draws_beta_mu[[1]])){
x <- sapply(1:length(draws_beta_mu), function(chain){
draws_beta_mu[[chain]][,i]
}) # x is set of column i across draws_beta_mu
fit_stats$mean[i] <- round(mean(x), 2)
fit_stats$rhat[i] <- round(rhat(x),2)
fit_stats$ESS[i] <- round(ess_basic(x),1)
plot(x[,1], type = "l", col = chain_cols[1], ylim = c(min(x), max(x)),
xlab = "Sample Iteration", ylab = "Mean Beta",
main = paste(colnames(code_master)[i],
"| rhat = ", round(rhat(x),2),
"| ESS = ", round(ess_basic(x),1)
))
for (chain in 2:nchains){
lines(x[,2], type = "l", col = chain_cols[chain])
}
}
dev.off()
write.table(fit_stats, file = file.path(dir_work, paste0(out_prefix,"_fit_stats.csv")), sep = ",", na = ".", row.names = FALSE)
}
checkconverge_export(stan_outname, data_stan$code_master, data_stan$I,
nchains = HB_fit$num_chains(), dir$stanout, out_prefix, dir$work)
checkconverge_export
source("https://raw.githubusercontent.com/klattery/Estimation-Ecosystem/master/EE_Functions_Stan2.R")
checkconverge_export(stan_outname, data_stan$code_master, data_stan$I,
nchains = HB_fit$num_chains(), dir$stanout, out_prefix, dir$work)
process_utilities(data_stan, utilities, out_prefix, dir$work)
write.table(cbind(data_stan$idtask, dep = data_stan$dep, wts = data_stan$wts, pred_all), file = file.path(dir_work, pred_name), sep = ",", na = ".", row.names = FALSE)
write.table(cbind(data_stan$idtask, dep = data_stan$dep, wts = data_stan$wts, pred = pred_all), file = file.path(dir_work, pred_name), sep = ",", na = ".", row.names = FALSE)
source("https://raw.githubusercontent.com/klattery/Estimation-Ecosystem/master/EE_Functions_Stan2.R")
source("https://raw.githubusercontent.com/klattery/Estimation-Ecosystem/master/EE_Functions_Stan2.R")
process_utilities(data_stan, utilities, out_prefix, dir$work)
process_utilities(data_stan, utilities, out_prefix, dir$work)
source("https://raw.githubusercontent.com/klattery/Estimation-Ecosystem/master/EE_Functions_Stan2.R")
process_utilities(data_stan, utilities, out_prefix, dir$work)
process_utilities
rm(env_eb)
rm(en_stan)
rm(env_stan)
em(env_code)
rm(env_code)
rm(env_modfun)
source("https://raw.githubusercontent.com/klattery/Estimation-Ecosystem/master/EE_Functions_Stan2.R")
process_utilities(data_stan, utilities, out_prefix, dir$work)
# 6) Optional Empirical Bayes =============
eb_betas_est(data_stan, draws_beta, colMeans(utilities), r_cores,
out_prefix, dir$work, cov_scale = 1, linux = FALSE)
source("https://raw.githubusercontent.com/klattery/Estimation-Ecosystem/master/EE_Functions_Stan2.R")
process_utilities(data_stan, utilities, out_prefix, dir$work)
# 6) Optional Empirical Bayes =============
eb_betas_est(data_stan, draws_beta, colMeans(utilities), r_cores,
out_prefix, dir$work, cov_scale = 1, linux = FALSE)
ind <- matrix(rnorm(670000*132), 670000, 132)
ksvd <- svd(cor(ind))
my_e <- eigen(cor(ind))
my_e[[1]]
ksvd$d
x <- cor(ind)
my_e <- eigen(x,only.values = TRUE)
my_e <- eigen(x,only.values = TRUE, symmetric = TRUE)
? cor
my_e <- eigen(ind,only.values = TRUE, symmetric = FALSE)
my_e <- eigen(ind %*% t(ind),only.values = TRUE, symmetric = FALSE)
my_e <- eigen(t(ind) %*% (ind),only.values = TRUE, symmetric = FALSE)
ind_z <- scale(ind)
my_e <- eigen(t(ind_z) %*% (ind_z),only.values = TRUE, symmetric = TRUE)
x <- cor(ind)
sessionInfo()
x <- cor(ind)
x2 <- crossprod(scale(ind, TRUE, TRUE))/(nrow(x)-1)
install.packages("coop")
library(coop)
coop::pcor(ind)
x2 <- coop::pcor(ind)
x2 <- crossprod(scale(ind, TRUE, TRUE))/(nrow(x)-1)
a <- Sys.time()
x2 <- crossprod(scale(ind, TRUE, TRUE))/(nrow(x)-1)
Sys.time()-a
a <- Sys.time()
x2 <- coop::pcor(ind)
Sys.time()-a
a <- Sys.time()
x <- cor(ind)
Sys.time()-a
? cor
x2 <- cor(ind, nThreads = 4)
sessionInfo()
a <- Sys.time()
x <- cor(ind)
Sys.time()-a # 7.23
a <- Sys.time()
x2 <- crossprod(scale(ind, TRUE, TRUE))/(nrow(x)-1)
Sys.time()-a #10.26
a <- Sys.time()
x2 <- coop::pcor(ind)
Sys.time()-a #4.73
plot(x,x2)
max(abs(x - x2))
